{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrameWriter as W\n",
    "from pyspark.sql.types import StringType,FloatType,DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf,col, countDistinct\n",
    "\n",
    "MODULE_NAME='locator'\n",
    "VERSION='0.01'\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "def get_module_name():\n",
    "    return MODULE_NAME\n",
    "\n",
    "def get_module_version():\n",
    "    return VERSION\n",
    "    \n",
    "\n",
    "def get_dataset(file_location, file_type, infer_schema=\"false\", has_header=\"true\", delimiter=\",\"):\n",
    "   df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", has_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .option(\"charset\", \"utf-8\") \\\n",
    "  .load(file_location)\n",
    "\n",
    "   return df\n",
    "\n",
    "def get_country_info():\n",
    "    \n",
    "    file_location = \"wikipedia-iso-country-codes.csv\"\n",
    "    file_type = \"csv\"\n",
    "    df_country_info = get_dataset(file_location, file_type, delimiter=\",\")\n",
    "    df_country_info_renamed = df_country_info.select(col(\"English short name lower case\").alias(\"Country_Name\"), \n",
    "                              col(\"Alpha-2 code\").alias(\"ALPHA2\"),col(\"Alpha-3 code\").alias(\"ALPHA3\"))\n",
    "    return df_country_info_renamed\n",
    "\n",
    "def filter_data(input_df,filter_key, filter_value):\n",
    "    return input_df.filter(input_df[filter_key] == filter_value)\n",
    "\n",
    "#Get Distance between 2 coordinates using Haversine Algorithm\n",
    "def get_distance(lon_a, lat_a, lon_b, lat_b):\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    # Transform to radians\n",
    "    lon_a, lat_a, lon_b, lat_b = map(radians, [lon_a, lat_a, lon_b, lat_b])    \n",
    "    # Calculare distance between lon/lat\n",
    "    dist_between_lon = lon_b - lon_a\n",
    "    dist_between_lat = lat_b - lat_a  \n",
    "    # Calculate area\n",
    "    area = sin(dist_between_lat/2)**2 + cos(lat_a) * cos(lat_b) * sin(dist_between_lon/2)**2  \n",
    "    # Calculate the central angle\n",
    "    central_angle = 2 * asin(sqrt(area))\n",
    "    # Calculate Distance\n",
    "    earth_radius = 6371\n",
    "    distance_in_km = central_angle * earth_radius\n",
    "    \n",
    "    return abs(round(distance_in_km,1))\n",
    "\n",
    "def string_to_float(x): \n",
    "    return float(x)\n",
    "\n",
    "\n",
    "#User-Defined Functions Here\n",
    "udf_string_to_float = udf(string_to_float, StringType())\n",
    "udf_get_distance = F.udf(get_distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_isolated_stores_per_country(df_stores, country_name):\n",
    "    #df_starbucks_au = filter_data(df_starbucks_stores_with_country_name, 'Country', country_name )\n",
    "    df_stores = filter_data(df_stores, 'Country', country_name )\n",
    "    #Use dataset with few columns/features for easy analysis\n",
    "    df_stores_locations_only = df_stores.select(\"STORE NUMBER\",\"STORE NAME\",\"LATITUDE\",\"LONGITUDE\")\n",
    "\n",
    "    #Do a cross-join to perform column operations and renaming\n",
    "    #This will pair each location to every location in the list\n",
    "    df_stores_location_pairs = df_stores_locations_only.crossJoin(df_stores_locations_only)\\\n",
    "                                .toDF(\"STORE_NUMBER_A\", \"STORE_NAME_A\", \"LATITUDE_A\", \"LONGITUDE_A\",\n",
    "                                \"STORE_NUMBER_B\", \"STORE_NAME_B\", \"LATITUDE_B\", \"LONGITUDE_B\")\n",
    "    #Clean up. Remove repeated rows\n",
    "    df_stores_pairs = (df_stores_location_pairs\n",
    "                      .filter(df_stores_location_pairs.STORE_NUMBER_A \n",
    "                      != df_stores_location_pairs.STORE_NUMBER_B))\n",
    "\n",
    "    #Now get absolute distance between the pairs by calling the get_distance function\n",
    "    df_store_pairs_with_distance = (df_stores_pairs.withColumn\n",
    "                               (\"ABS_DISTANCE\", udf_get_distance(df_stores_pairs.LONGITUDE_A,\n",
    "                                                                 df_stores_pairs.LATITUDE_A,\n",
    "                                                                 df_stores_pairs.LONGITUDE_B,\n",
    "                                                                 df_stores_pairs.LATITUDE_B).cast(DoubleType())))\n",
    "    #Sort Ascending\n",
    "    df_store_pairs_with_distance = df_store_pairs_with_distance\\\n",
    "                                      .select(\"STORE_NUMBER_A\",\"STORE_NAME_A\",\n",
    "                                              \"STORE_NUMBER_B\",\"STORE_NAME_B\",\n",
    "                                              \"ABS_DISTANCE\").orderBy(\"ABS_DISTANCE\")\n",
    "    '''\n",
    "    - Apply min-max algorithm\n",
    "    - First, sort by abs_distance in ascending order\n",
    "    - Get the minimum nearest distance for each group\n",
    "    - \n",
    "    '''\n",
    "    #Group per store to its nearest_neighboor\n",
    "    windowSpec = Window.partitionBy(df_store_pairs_with_distance['STORE_NUMBER_A']).orderBy('ABS_DISTANCE')\n",
    "    min_nearest_store_distance = F.first(df_store_pairs_with_distance['ABS_DISTANCE']).over(windowSpec)\n",
    "    \n",
    "    df_store_pairs_with_min_distance = df_store_pairs_with_distance\\\n",
    "            .select(df_store_pairs_with_distance['STORE_NUMBER_A']\n",
    "            ,df_store_pairs_with_distance['STORE_NAME_A']\n",
    "            ,df_store_pairs_with_distance['STORE_NUMBER_B']\n",
    "            ,df_store_pairs_with_distance['STORE_NAME_B']\n",
    "            ,df_store_pairs_with_distance['ABS_DISTANCE'],min_nearest_store_distance.alias('min_nearest_distance'))\n",
    "\n",
    "    #Generate dataset with minimum nearest neighboor distance.\n",
    "    df_stores_isolated = df_store_pairs_with_min_distance\\\n",
    "                        .filter(col(\"ABS_DISTANCE\") == col(\"min_nearest_distance\"))\\\n",
    "                        .orderBy(\"min_nearest_distance\",ascending=False)\n",
    "    \n",
    "    return df_stores_isolated.collect()\n",
    "    \n",
    "    \n",
    "def get_most_isolated_store_per_country(df, country):\n",
    "    out_df = get_isolated_stores_per_country(df, country)\n",
    "    return {\n",
    "        \"store_name\": out_df[0]['STORE_NAME_A'],\n",
    "        \"store_number\": out_df[0]['STORE_NUMBER_A'],\n",
    "        \"nearest_store\": out_df[0]['STORE_NAME_B'],\n",
    "        \"nearest_distance_km\": out_df[0]['min_nearest_distance']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_count_per_country(df):\n",
    "    \n",
    "    df_stores_agg = df.groupBy(\"Country_Name\").agg(F.count(\"Store Number\").alias('Store_Count')).orderBy(col(\"Store_Count\"))\n",
    "    df_country_info = get_country_info()\n",
    "    \n",
    "    df_stores_agg_joined = df_stores_agg.join(df_country_info,\\\n",
    "        df_stores_agg.Country_Name == df_country_info.Country_Name,how='left')\n",
    "    df_stores_agg_joined = df_stores_agg_joined.select(df_stores_agg['Country_Name']\\\n",
    "                          ,df_stores_agg_joined['AlPHA2']\\\n",
    "                          ,df_stores_agg_joined['ALPHA3']\\\n",
    "                          ,df_stores_agg_joined['Store_Count'])\n",
    "    \n",
    "    #df_stores_agg_joined.show()\n",
    "    \n",
    "    return  df_stores_agg_joined\n",
    "\n",
    "def get_country_store_count(df, country):\n",
    "    out_df = get_store_count_per_country(df)\n",
    "    out_df = out_df.filter(out_df.AlPHA2 == country ).collect()\n",
    "    \n",
    "    return out_df[0]['Store_Count']\n",
    "    \n",
    "def get_minimum_count(df, col_name):\n",
    "    return df.select(F.min(col_name).alias('count')).collect()[0]\n",
    "\n",
    "def get_countries_with_least_starbucks_stores(df):\n",
    "    out_df = get_store_count_per_country(df)\n",
    "    min_count = get_minimum_count(out_df, 'Store_Count')\n",
    "    countries_with_least_stores_df = out_df.where(out_df.Store_Count == min_count['count'])\n",
    "    \n",
    "    return countries_with_least_stores_df.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
